```{r setup, include=FALSE}
library(tidytext)
library(ggplot2)
library(tm)
library(quanteda)
library(RColorBrewer)
library(topicmodels)
library(tidyr)
library(dplyr)
library(stringr)
library(readr)
library(jsonlite)
library(stringdist)
library(wordcloud)

# install.packages("Rwordseg", repos="http://R-Forge.R-project.org")
library(Rwordseg)
# install.packages("tmcn", repos="http://R-Forge.R-project.org", type="source")
library(tmcn)

install.packages('extrafont')
library(extrafont)

font_import(pattern = 'GARAIT')
```

```{r}
ch_rev = read.csv("/students/dvchuprina/proect_kutezh/ch_rev.csv")
rev_train <- data.frame(head(ch_rev,500))
rm(ch_rev)

rev_train <- read.csv("~/proect_kutezh/rev_train.csv")

stop_words = read.table("~/proect_kutezh/stopwords-zh.txt")
#tr_mcc_codes = tidyr::separate(tr_mcc_codes, mcc_codemcc_description, c("mcc_code", "mcc_description"), ";")
names(stop_words)[1] = "word"
stop_words$word <- as.character(stop_words$word)

#  готовые стоп-слова (removed 不，不是)
stop = as.data.frame(stop_words[-c(24,41),])
stop_w_ready = stop
# write.csv(stop_w_ready, "stop_w_ready.csv", row.names = F)


rev_train$restId = rev_train$restId %>% as.factor()
rev_train$content = rev_train$content %>% as.character()

write.csv(rev_train, "rev_train.csv", row.names = F)

```

```{r}
# install dictionnaries
installDict("/students/dvchuprina/proect_kutezh/restaurantsdict.scel", dictname = "restdict")
installDict("/students/dvchuprina/proect_kutezh/chinesefooddict.scel", dictname = "chfooddict")
installDict("/students/dvchuprina/proect_kutezh/shanghaidict.scel", dictname = "shanghaidict")

installDict("/students/dvchuprina/proect_kutezh/chatdict.scel", dictname = "chatdict")
installDict("/students/dvchuprina/proect_kutezh/chengyudict.scel", dictname = "chengyudict")
installDict("/students/dvchuprina/proect_kutezh/beijingdict.scel", dictname = "beijingdict")
installDict("/students/dvchuprina/proect_kutezh/americanproductsdict.scel", dictname = "americanfooddict")

installDict("/students/dvchuprina/proect_kutezh/products.scel", dictname = "productsict")
installDict("/students/dvchuprina/proect_kutezh/greatcuisinedict.scel", dictname = "greatcuisinedict")

installDict("/students/dvchuprina/proect_kutezh/food.scel", dictname = "fooddict")

```

```{r}
# HAVING FUN WITH FIRST 100 RESTS
a1 = read.csv("~/proect_kutezh/first100.csv")
rev_cor = Corpus(VectorSource(a1$content), readerControl = list(reader = readPlain, language = "cn"))
rev_cor <- tm_map(rev_cor, removePunctuation)
rev_cor <- tm_map(rev_cor, removeNumbers)
rev_cor <- tm_map(rev_cor, function(word) {
    gsub("[A-Za-z0-9]", "", word)
})

# segmenting the text

rev = lapply(rev_cor, function(x) unlist(segmentCN(x)))
rest = Corpus(VectorSource(rev), readerControl = list(reader = readPlain, encoding = "UTF-8", language = "cn"))
inspect(rest[2])

stopw = read.csv("/students/dvchuprina/proect_kutezh/stop_w_ready.csv")
colnames(stopw) = "word"
stop = str_c(stopw$word, sep = ",")

mystop = c(stopwordsCN(), stop, "一下", "一份", "一块", "一定", "一家", "一层", "一年", "一张", "一次", "一点", "一碗", "一种", "一起", "一边", "一两片", "一个多", "一元", "一共", "一半一半", "一口", "一句", "一向", "一堆", "一墙之隔", "一批", "一把", "一斤", "一模一样", "一点点", "一瓶", "一盘", "一篇", "一群", "一致", "一行", "一道", "一间", "一阵", "一阵", "一遍", "丁", "上来", "上班", "上面", "下次", "不", "不同", "不少", "不知", "不能", "不错", "天", "很多","现", "买", "值得","可能","看到", "经常", "里", "面", "加", "附近", "里面", "事", "两", "中午", "两个", "两种", "个人", "之前", "以前", "以后", "前", "卖", "对面", "没", "没有", "这家", "这", "家", "外面", "两层", "几种", "起来", "常常", "吃", "喜欢", "喝", "边上", "份", "他家", "偏", "几个", "几乎", "几次", "出", "吃饭", "刚", "后来", "听", "回", "回来", "地方", "太", "朋友", "门", "门口", "层", "丢", "七十", "三个", "三四十", "三次", "三碗", "上去", "上次", "下去", "下来", "下降", "下面", "下饭", "不上了", "不住", "不准", "不够", "不大不小", "不易", "不用", "不知道了", "不算", "不要", "专", "专业", "专人", "两块", "两年", "两样", "两次", "两碗", "两面块", "丫头", "中等", "中间", "临时", "丸", "为主", "主要", "主题", "主食", "久", "之后", "乍", "九次", "也许", "习惯性", "二楼", "五份", "五块", "五种", "交叉口", "交涉", "交通", "人均", "人士", "人气", "什么时候","今天", "份量", "仿佛", "优缺点", "传统", "估计", "伴", "似", "似乎", "位", "位子", "位置", "住", "体现", "俗", "保", "倒", "倒是", "倒腾", "倒闭", "值", "做饭", "停", "停车", "停车位", "偶尔", "偶然", "元", "先", "先是", "光", "光顾", "入冬", "全", "八卦", "公", "公司", "关系", "其实", "具有", "再也", "写", "决定", "准备", "准确", "凑", "凑合", "几分钟", "几十年")

mystop = c(mystop,"几十次", "几千", "几块", "几多", "几天", "几样", "凸", "出入", "分享", "分量", "切", "划算", "列为", "刚吃完", "初一", "制止", "刷", "前前后后", "前台", "前面", "办", "办公桌", "功", "加上", "加入", "十一", "十八块", "十字路口", "十次", "半", "半圆", "半天", "半左右", "半截", "单一", "单人", "单位", "印象", "压阵", "原因", "原来", "去呀", "去掉", "参加", "参观", "及时", "反", "反正", "反馈", "发", "发展", "发现", "发生", "发言", "受", "口", "句", "台", "吃啊", "同样", "名字", "听说", "吹", "告诉", "周", "周围", "呼", "品", "品吧", "品种", "响应", "哈哈哈哈哈", "哗啦", "唠叨", "唯一", "喉", "喔", "喝多了", "嗓子", "嗜", "嘟囔", "噔", "器皿", "嚼", "四五个", "	四十多", "四周", "回去", "回头", "一个点", "一半", "一回", "一盆", "占", "一丝", "一个个", "一会儿", "一位", "一刻", "一周", "一圈", "一天", "一头", "一度", "一座", "一晃", "一杯", "一桌", "一款", "一点一滴", "一点儿", "一片", "一股", "一般吧", "一般啊", "一英寸", "一贯", "一路", "一连串", "一颗", "万分", "三分", "三处", "三户", "上司", "上层", "上楼", "上班族", "上相", "上网", "下功夫", "下雨", "不一定", "不久", "不再" , "不变", "不可", "不大", "不得不", "不明", "不明白", "不知何故", "不管了", "不给看", "不肯", "不能自己", "不论是", "世界", "业务", "两三个", "两两", "两分钟", "两勺", "两口", "两周", "两天", "两家", "两杯", "两滴", "个个", "临街", "主动", "之外", "之间","乐趣", "书", "程度", "突然", "窗", "立", "站", "竟然", "端", "笑", "第一", "第一次", "第三", "第个", "第二次", "第四", "第二", "简直", "算", "算了", "店", "点", "环境", "特别", "比较", "觉得", "服务员", "坐", "少", "总体", "推荐", "差", "感觉", "普通", "真", "挺", "服务", "铁")
mystop = c(mystop, "进去","这种","时间","进","布","摩","当时", "走","累","非常","杯","逛","昨天","过来","已经","想","店面","总", "找","区","完","足","楼下","帮","改","送","速度","量","试","特","式","每次","沙","爱","沙发","钱","抹","知道","带","店员","座","老","基本","当日","干","现在", "话", "有点","座位","需要","换","大概","快","没什么","类","态度","装修","不以为然","强制","继续","充足","商","平常")
rest2 = tm_map(rest, removeWords, mystop) 
inspect(rest2[2])

tdm <- DocumentTermMatrix(rest2[3:6])
tdm= removeSparseTerms(tdm, 0.9)  # убирает редкие слова 
inspect(t(tdm))

findFreqTerms(tdm, 5)   #ищет частые слова

findAssocs(t(tdm), "不", 0.5) #ищет частые употребления (вдруг пригодится)
library(extrafont)
fonttable()


m1 = as.matrix(t(tdm))
v <- sort(rowSums(m1), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v)
wordcloud(d$word, d$freq, min.freq = 50, random.order = F, ordered.colors = F, colors = rainbow(length(row.names(m1))))


ap_lda <- LDA(tdm, k = 2, control = list(seed = 1234))
ap_lda
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics

ap_top_terms <- ap_topics %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

ap_top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()

ap_documents <- tidy(ap_lda, matrix = "gamma")
ap_documents

#tidy(AssociatedPress) %>%
# filter(document == 6) %>%
# arrange(desc(count))
```

```{r}
# BINDING ALL DATASETS TOGETHER
rev_full_ready = rbind(first100, r101_500, r501_1000, r1001_2000, r2001_2500, r2501_3000, r3001_3501, r3501_5500, r5500-r8500, r8501_10000, r10001_11000, r11_12, )
```

